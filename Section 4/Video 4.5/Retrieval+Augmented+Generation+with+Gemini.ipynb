{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2328f4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gsutil\n",
      "  Downloading gsutil-5.27.tar.gz (3.0 MB)\n",
      "Collecting argcomplete>=1.9.4\n",
      "  Downloading argcomplete-3.2.1-py3-none-any.whl (42 kB)\n",
      "Collecting crcmod>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "Collecting fasteners>=0.14.1\n",
      "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Collecting gcs-oauth2-boto-plugin>=3.0\n",
      "  Downloading gcs-oauth2-boto-plugin-3.0.tar.gz (20 kB)\n",
      "Collecting google-apitools>=0.5.32\n",
      "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
      "Collecting httplib2==0.20.4\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "Collecting google-reauth>=0.1.0\n",
      "  Downloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting monotonic>=1.4\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=0.13 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from gsutil) (21.0.0)\n",
      "Collecting retry_decorator>=1.0.0\n",
      "  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: six>=1.16.0 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from gsutil) (1.16.0)\n",
      "Requirement already satisfied: google-auth[aiohttp]>=2.5.0 in c:\\users\\renal\\appdata\\roaming\\python\\python39\\site-packages (from gsutil) (2.25.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from httplib2==0.20.4->gsutil) (3.0.4)\n",
      "Collecting rsa==4.7.2\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting boto>=2.29.1\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting oauth2client>=2.2.0\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (5.3.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0.dev0,>=3.6.2 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (3.8.4)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.20.0 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (2.27.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0.dev0,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0.dev0,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0.dev0,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0.dev0,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0.dev0,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0.dev0,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0.dev0,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.8.2)\n",
      "Collecting pyu2f\n",
      "  Downloading pyu2f-0.1.5.tar.gz (27 kB)\n",
      "Requirement already satisfied: cryptography>=3.3 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.13->gsutil) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from cryptography>=3.3->pyOpenSSL>=0.13->gsutil) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\renal\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.3->pyOpenSSL>=0.13->gsutil) (2.21)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\renal\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (2021.10.8)\n",
      "Building wheels for collected packages: gsutil, crcmod, gcs-oauth2-boto-plugin, retry-decorator, pyu2f\n",
      "  Building wheel for gsutil (setup.py): started\n",
      "  Building wheel for gsutil (setup.py): finished with status 'done'\n",
      "  Created wheel for gsutil: filename=gsutil-5.27-py3-none-any.whl size=3785301 sha256=2117686b8f95971d7e4843bc5160b45f14672f9b86eaeac0c9e07638aa56dba1\n",
      "  Stored in directory: c:\\users\\renal\\appdata\\local\\pip\\cache\\wheels\\de\\7e\\15\\d4fc45223984db92cbe31d7cd0d85c30bc2a0e0fc8753764fd\n",
      "  Building wheel for crcmod (setup.py): started\n",
      "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-win_amd64.whl size=25135 sha256=7999638b546ee19c709d126f048321817ef819d21d5f3dbd4cf1630af2063436\n",
      "  Stored in directory: c:\\users\\renal\\appdata\\local\\pip\\cache\\wheels\\4a\\6c\\a6\\ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
      "  Building wheel for gcs-oauth2-boto-plugin (setup.py): started\n",
      "  Building wheel for gcs-oauth2-boto-plugin (setup.py): finished with status 'done'\n",
      "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.0-py3-none-any.whl size=23220 sha256=d12dcc5b37f5a474369e444795265d7d4383dcbe937a153805e9734b0a80779b\n",
      "  Stored in directory: c:\\users\\renal\\appdata\\local\\pip\\cache\\wheels\\f1\\40\\ff\\39d839bc4fba3fe04886bba7931d11813caf5a0b485c372714\n",
      "  Building wheel for retry-decorator (setup.py): started\n",
      "  Building wheel for retry-decorator (setup.py): finished with status 'done'\n",
      "  Created wheel for retry-decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3638 sha256=507c18b2514b8fdc044879b0fa1823f177076e857f69e4af654efd9c63b7f0ce\n",
      "  Stored in directory: c:\\users\\renal\\appdata\\local\\pip\\cache\\wheels\\fd\\09\\f6\\38dc5c7945cdae80d1d0e6717f891e95d70d5b1926a92b931f\n",
      "  Building wheel for pyu2f (setup.py): started\n",
      "  Building wheel for pyu2f (setup.py): finished with status 'done'\n",
      "  Created wheel for pyu2f: filename=pyu2f-0.1.5-py3-none-any.whl size=39403 sha256=5d45c93681bda250cb5a603d0e1196c2f782934cdf23685037fa042e3de99533\n",
      "  Stored in directory: c:\\users\\renal\\appdata\\local\\pip\\cache\\wheels\\46\\3b\\95\\d2e12a506ead5f6f8b54b0df8e40ab653c2fb9c0379f247eaa\n",
      "Successfully built gsutil crcmod gcs-oauth2-boto-plugin retry-decorator pyu2f\n",
      "Installing collected packages: rsa, pyu2f, httplib2, retry-decorator, oauth2client, google-reauth, fasteners, boto, monotonic, google-apitools, gcs-oauth2-boto-plugin, crcmod, argcomplete, gsutil\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "Successfully installed argcomplete-3.2.1 boto-2.49.0 crcmod-1.7 fasteners-0.19 gcs-oauth2-boto-plugin-3.0 google-apitools-0.5.32 google-reauth-0.1.1 gsutil-5.27 httplib2-0.20.4 monotonic-1.6 oauth2client-4.1.3 pyu2f-0.1.5 retry-decorator-1.1.1 rsa-4.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d573fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.getenv('GCP_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea343ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-pro-vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0f1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from vertexai.preview.generative_models import (\n",
    "    Content,\n",
    "    GenerationConfig,\n",
    "    GenerationResponse,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c80f9",
   "metadata": {},
   "source": [
    "### Download custom Python modules and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9e46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import sys\n",
    "\n",
    "if not os.path.exists(\"utils\"):\n",
    "    os.makedirs(\"utils\")\n",
    "\n",
    "    \n",
    "# download the helper scripts from utils folder\n",
    "url_prefix = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/retrieval-augmented-generation/utils/\"\n",
    "files = [\"intro_multimodal_rag_utils.py\"]\n",
    "\n",
    "for fname in files:\n",
    "    urllib.request.urlretrieve(f\"{url_prefix}/{fname}\", filename=f\"utils/{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d828cc0",
   "metadata": {},
   "source": [
    "### Get documents and images from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5853e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronization completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building synchronization state...\n",
      "Starting synchronization...\n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/text_query_answer_02.png...\n",
      "/ [0/5 files][    0.0 B/823.1 KiB]   0% Done                                    \n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/google-10k-sample-14pages.pdf...\n",
      "/ [0/5 files][    0.0 B/823.1 KiB]   0% Done                                    \n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/class_a_share.png...\n",
      "/ [0/5 files][    0.0 B/823.1 KiB]   0% Done                                    \n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/tac_table_revenue.png...\n",
      "/ [0/5 files][    0.0 B/823.1 KiB]   0% Done                                    \n",
      "-\n",
      "- [1/5 files][ 26.4 KiB/823.1 KiB]   3% Done                                    \n",
      "- [2/5 files][ 95.0 KiB/823.1 KiB]  11% Done                                    \n",
      "Copying gs://github-repo/rag/intro_multimodal_rag/text_query_answer_01.png...\n",
      "- [2/5 files][ 95.0 KiB/823.1 KiB]  11% Done                                    \n",
      "- [3/5 files][168.4 KiB/823.1 KiB]  20% Done                                    \n",
      "\\\n",
      "\\ [4/5 files][554.6 KiB/823.1 KiB]  67% Done                                    \n",
      "\\ [5/5 files][823.1 KiB/823.1 KiB] 100% Done                                    \n",
      "\n",
      "Operation completed over 5 objects/823.1 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# download documents and images used in this notebook\n",
    "!gsutil -m rsync -r gs://github-repo/rag/intro_multimodal_rag .\n",
    "print(\"Synchronization completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fff266",
   "metadata": {},
   "source": [
    "### Extract and store metadata of text and images from a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ffa8af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading PyMuPDF-1.23.7-cp39-none-win_amd64.whl (3.5 MB)\n",
      "Collecting PyMuPDFb==1.23.7\n",
      "  Downloading PyMuPDFb-1.23.7-py3-none-win_amd64.whl (24.5 MB)\n",
      "Installing collected packages: PyMuPDFb, pymupdf\n",
      "Successfully installed PyMuPDFb-1.23.7 pymupdf-1.23.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ea65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.intro_multimodal_rag_utils import get_document_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e22ab250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page: 1\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m image_description_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mExplain what is going on in the image.\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124mIf it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms a table, extract all elements of the table. \u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mIf it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms a graph, explain the findings in the graph.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mDo not include any numbers that are not mentioned in the image:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Extract text and image metadata from the PDF document\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m text_metadata_df, image_metadata_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_document_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-test-project-408107\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Assuming this is a positional argument\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# Assuming this is a positional argument\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_description_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_description_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1408\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_emb_text_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Completed processing. ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Github\\generative-ai\\gemini\\gemini-notebooks\\utils\\intro_multimodal_rag_utils.py:550\u001b[0m, in \u001b[0;36mget_document_metadata\u001b[1;34m(project_id, generative_multimodal_model, pdf_path, image_save_dir, image_description_prompt, embedding_size, text_emb_text_limit)\u001b[0m\n\u001b[0;32m    542\u001b[0m page \u001b[38;5;241m=\u001b[39m doc[page_num]\n\u001b[0;32m    544\u001b[0m text \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mget_text()\n\u001b[0;32m    545\u001b[0m (\n\u001b[0;32m    546\u001b[0m     text,\n\u001b[0;32m    547\u001b[0m     page_text_embeddings_dict,\n\u001b[0;32m    548\u001b[0m     chunked_text_dict,\n\u001b[0;32m    549\u001b[0m     chunk_embeddings_dict,\n\u001b[1;32m--> 550\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mget_chunk_text_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;66;03m# print(text, page_text_embeddings_dict, chunked_text_dict, chunk_embeddings_dict)\u001b[39;00m\n\u001b[0;32m    552\u001b[0m text_metadata[page_num] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage_text_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: page_text_embeddings_dict,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunked_text_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: chunked_text_dict,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_embeddings_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: chunk_embeddings_dict,\n\u001b[0;32m    557\u001b[0m }\n",
      "File \u001b[1;32m~\\Documents\\Github\\generative-ai\\gemini\\gemini-notebooks\\utils\\intro_multimodal_rag_utils.py:325\u001b[0m, in \u001b[0;36mget_chunk_text_metadata\u001b[1;34m(project_id, page, character_limit, overlap, embedding_size)\u001b[0m\n\u001b[0;32m    322\u001b[0m text: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Get whole-page text embeddings\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m page_text_embeddings_dict: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mget_page_text_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_size\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Chunk the text with the given limit and overlap\u001b[39;00m\n\u001b[0;32m    330\u001b[0m chunked_text_dict: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m get_text_overlapping_chunk(text, character_limit, overlap)\n",
      "File \u001b[1;32m~\\Documents\\Github\\generative-ai\\gemini\\gemini-notebooks\\utils\\intro_multimodal_rag_utils.py:280\u001b[0m, in \u001b[0;36mget_page_text_embedding\u001b[1;34m(project_id, text_data, embedding_size)\u001b[0m\n\u001b[0;32m    277\u001b[0m         embeddings_dict[chunk_number] \u001b[38;5;241m=\u001b[39m text_embd\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# Process the first 1000 characters of the page text\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     text_embd \u001b[38;5;241m=\u001b[39m \u001b[43mget_text_embedding_from_text_embedding_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_size\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m     embeddings_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m text_embd\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings_dict\n",
      "File \u001b[1;32m~\\Documents\\Github\\generative-ai\\gemini\\gemini-notebooks\\utils\\intro_multimodal_rag_utils.py:50\u001b[0m, in \u001b[0;36mget_text_embedding_from_text_embedding_model\u001b[1;34m(project_id, text, embedding_size)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03mReturns an embedding (as a list) based on input text, using a multimodal embedding modal:\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mmultimodalembedding@001\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    A list representing the text embedding.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Create a client to interact with the Vertex AI Prediction Service\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43maiplatform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgapic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPredictionServiceClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapi_endpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-central1-aiplatform.googleapis.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Specify the endpoint of the deployed multimodal embedding model\u001b[39;00m\n\u001b[0;32m     55\u001b[0m endpoint_multimodalembedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/locations/us-central1/publishers/google/models/multimodalembedding@001\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\client.py:464\u001b[0m, in \u001b[0;36mPredictionServiceClient.__init__\u001b[1;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[0;32m    459\u001b[0m     credentials \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39m_default\u001b[38;5;241m.\u001b[39mget_api_key_credentials(\n\u001b[0;32m    460\u001b[0m         api_key_value\n\u001b[0;32m    461\u001b[0m     )\n\u001b[0;32m    463\u001b[0m Transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget_transport_class(transport)\n\u001b[1;32m--> 464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mTransport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_cert_source_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\grpc.py:154\u001b[0m, in \u001b[0;36mPredictionServiceGrpcTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[0;32m    150\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[0;32m    151\u001b[0m             )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel(\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host,\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;66;03m# use the credentials which are saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m         ],\n\u001b[0;32m    180\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\cloud\\aiplatform_v1\\services\\prediction_service\\transports\\base.py:103\u001b[0m, in \u001b[0;36mPredictionServiceTransport.__init__\u001b[1;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[0;32m    100\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[0;32m    105\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\google\\auth\\_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    683\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[0;32m    688\u001b[0m             )\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "# Specify the PDF path\n",
    "pdf_path = \"google-10k-sample-14pages.pdf\"\n",
    "\n",
    "# Specify the image description prompt. Change it\n",
    "image_description_prompt = \"\"\"Explain what is going on in the image.\n",
    "If it's a table, extract all elements of the table. \n",
    "If it's a graph, explain the findings in the graph.\n",
    "Do not include any numbers that are not mentioned in the image:\"\"\"\n",
    "\n",
    "# Extract text and image metadata from the PDF document\n",
    "text_metadata_df, image_metadata_df = get_document_metadata(\n",
    "    \"gemini-test-project-408107\",  # Assuming this is a positional argument\n",
    "    model,                         # Assuming this is a positional argument\n",
    "    pdf_path=pdf_path,\n",
    "    image_save_dir=\"images\",\n",
    "    image_description_prompt=image_description_prompt,\n",
    "    embedding_size=1408,\n",
    "    text_emb_text_limit=1000\n",
    ")\n",
    "\n",
    "\n",
    "print(\"--- Completed processing. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3272776c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_metadata_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtext_metadata_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_metadata_df' is not defined"
     ]
    }
   ],
   "source": [
    "text_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c639edf",
   "metadata": {},
   "source": [
    "### Import the helper functions to implement RAGÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeebcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.intro_multimodal_rag_utils import (\n",
    "    get_similar_text_from_query,\n",
    "    print_text_to_text_citation,\n",
    "    get_similar_image_from_query,\n",
    "    print_text_to_image_citation,\n",
    "    get_gemini_response,\n",
    "    display_images,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b49ec",
   "metadata": {},
   "source": [
    "### Search similar text with text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I need details for basic and diluted net income per share of Class A, Class B, and Class C share for google?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5736f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching user text query with \"chunk_embedding\" to find relevant chunks.\n",
    "matching_results_text = get_similar_text_from_query(\n",
    "    PROJECT_ID,\n",
    "    query,\n",
    "    text_metadata_df,\n",
    "    column_name=\"text_embedding_chunk\",\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    "    chunk_text=True,\n",
    ")\n",
    "\n",
    "# Print the matched text citations\n",
    "print_text_to_text_citation(matching_results_text, print_top=True, chunk_text=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b939e",
   "metadata": {},
   "source": [
    "### Search similar images with text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05248db",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_results_image = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,\n",
    "    column_name=\"text_embedding_from_image_description\",  # Use image description text embedding\n",
    "    image_emb=False,  # Use text embedding instead of image embedding\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")\n",
    "\n",
    "# Markdown(print_text_to_image_citation(matching_results_image, print_top=True))\n",
    "print(\"\\n **** Result: ***** \\n\")\n",
    "\n",
    "# Display the top matching image\n",
    "display(matching_results_image[0][\"image_object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can check the citations to probe further.\n",
    "## check the \"image description:\" which is a description extracted through gemini which helped search our query.\n",
    "Markdown(print_text_to_image_citation(matching_results_image, print_top=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1007959",
   "metadata": {},
   "source": [
    "## Image Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11835b",
   "metadata": {},
   "source": [
    "### Search similar image with image query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291acf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Input image from user:***\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***Input image from user:***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display the input image\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mload_from_file(image_query_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# You can find a similar image as per the images you have in the metadata.\n",
    "# In this case, you have a table (picked from the same document source) and you would like to find similar tables in the document.\n",
    "image_query_path = \"tac_table_revenue.png\"\n",
    "\n",
    "# Print a message indicating the input image\n",
    "print(\"***Input image from user:***\")\n",
    "\n",
    "# Display the input image\n",
    "Image.load_from_file(image_query_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f851283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for Similar Images Based on Input Image and Image Embedding\n",
    "\n",
    "matching_results_image = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,  # Use query text for additional filtering (optional)\n",
    "    column_name=\"mm_embedding_from_img_only\",  # Use image embedding for similarity calculation\n",
    "    image_emb=True,\n",
    "    image_query_path=image_query_path,  # Use input image for similarity calculation\n",
    "    top_n=3,  # Retrieve top 3 matching images\n",
    "    embedding_size=1408,  # Use embedding size of 1408\n",
    ")\n",
    "\n",
    "print(\"\\n **** Result: ***** \\n\")\n",
    "\n",
    "# Display the Top Matching Image\n",
    "display(\n",
    "    matching_results_image[0][\"image_object\"]\n",
    ")  # Display the top matching image object (Pillow Image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c14162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display citation details for the top matching image\n",
    "print_text_to_image_citation(matching_results_image, print_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1628a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Other Matched Images (Optional)\n",
    "# You can access the other two matched images using:\n",
    "\n",
    "print(\"---------------Matched Images------------------\\n\")\n",
    "display_images(\n",
    "    [\n",
    "        matching_results_image[0][\"img_path\"],\n",
    "        matching_results_image[1][\"img_path\"],\n",
    "    ],\n",
    "    resize_ratio = 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5418a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_query_path = \"class_a_share.png\"\n",
    "\n",
    "# Print a message indicating the input image\n",
    "print(\"***Input image from user:***\")\n",
    "\n",
    "# Display the input image\n",
    "Image.load_from_file(image_query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff83fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image using Pillow\n",
    "user_image_object = Image.load_from_file(image_query_path)\n",
    "\n",
    "# Define the comparison query\n",
    "compare_query = \"\"\"Question: How has nasdaq performed with respect to Class A and Class B shares of Google?\n",
    "Answer: \"\"\"\n",
    "instructions = \"\"\"instructions: Compare two images and base your reasoning only on the images provided.\n",
    "Provide detail reasoning of your conclusions.\n",
    "Images: \"\"\"\n",
    "\n",
    "# Find similar images based on the input image\n",
    "image_selected_based_on_source_image = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    image_query_path=image_query_path,\n",
    "    column_name=\"mm_embedding_from_img_only\",\n",
    "    image_emb=True,\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")\n",
    "\n",
    "# Select the best matching image from the search results\n",
    "selected_image_object = image_selected_based_on_source_image[0][\"image_object\"]\n",
    "\n",
    "# Prepare the model input\n",
    "model_input = [instructions, user_image_object, selected_image_object, compare_query]\n",
    "\n",
    "# Generate Gemini response with streaming output\n",
    "Markdown(get_gemini_response(model, model_input=model_input, stream=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image selected by the model to make the comparision based on user query\n",
    "Image.load_from_file(image_selected_based_on_source_image[0][\"img_path\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be444115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# citations\n",
    "print_text_to_image_citation(image_selected_based_on_source_image, print_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02372f8",
   "metadata": {},
   "source": [
    "## Multimodal retrieval augmented generation (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf32af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time we are not passing any images, but just a simple text query.\n",
    "\n",
    "query = \"\"\"Question: How has nasdaq and s&p performed with respect to class A shares and class C shares?\n",
    "Which one would be better to buy and why?\n",
    "Answer: \"\"\"\n",
    "\n",
    "# query = \"\"\"Question: Find the total revenues and other related financial numbers for Alphabet\n",
    "# Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c56c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant chunks of text based on the query\n",
    "matching_results_chunks_data = get_similar_text_from_query(\n",
    "    PROJECT_ID,\n",
    "    query,\n",
    "    text_metadata_df,\n",
    "    column_name=\"text_embedding_chunk\",\n",
    "    top_n=5,\n",
    "    embedding_size=1408,\n",
    "    chunk_text=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all relevant images based on user query\n",
    "matching_results_image_fromdescription_data = get_similar_image_from_query(\n",
    "    PROJECT_ID,\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,\n",
    "    column_name=\"text_embedding_from_image_description\",\n",
    "    image_emb=False,\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57007892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the selected relevant text chunks\n",
    "context_text = []\n",
    "for key, value in matching_results_chunks_data.items():\n",
    "    context_text.append(value[\"chunk_text\"])\n",
    "final_context_text = \"\\n\".join(context_text)\n",
    "\n",
    "# combine all the relevant images and their description generated by Gemini\n",
    "context_images = []\n",
    "for key, value in matching_results_image_fromdescription_data.items():\n",
    "    context_images.extend(\n",
    "        [\"Image: \", value[\"image_object\"], \"Caption: \", value[\"image_description\"]]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba7b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"The context of extraction of destails should be based on the text context given in \"text_context\" and Image context given in \"image_context\" along with its Caption: \\n\n",
    "Base your response on \"text_context\" and \"image_context\". Do not use any numbers or percentages that are not present in the \"image_context\".\n",
    "Do not include any cumulative total return in the answer. Context: \n",
    "\"\"\"\n",
    "\n",
    "final_prompt = [\n",
    "    query,\n",
    "    instructions,\n",
    "    \"text_context:\",\n",
    "    \"\\n\".join(context_text),\n",
    "    \"image_context:\",\n",
    "]\n",
    "final_prompt.extend(context_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16efa2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(get_gemini_response(model, model_input = final_prompt,stream=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ab5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------Matched Images------------------\\n\")\n",
    "display_images(\n",
    "    [\n",
    "        matching_results_image_fromdescription_data[0][\"img_path\"],\n",
    "        matching_results_image_fromdescription_data[1][\"img_path\"],\n",
    "    ],\n",
    "    resize_ratio = 0.8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image citations. You can check how Gemini generated metadata helped in grounding the answer.\n",
    "\n",
    "print_text_to_image_citation(matching_results_image_fromdescription_data, print_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text citations\n",
    "\n",
    "print_text_to_text_citation(\n",
    "    matching_results_chunks_data,\n",
    "    print_top=False,\n",
    "    chunk_text=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
